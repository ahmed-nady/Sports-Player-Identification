{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Number detection and recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgjd5CIUhXkH"
      },
      "source": [
        "First: Number detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTdePXTEhLnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93377610-bf85-4125-c975-9c138e975e58"
      },
      "source": [
        "!git clone https://github.com/ahmed-nady/keras-ocr.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-ocr'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 856 (delta 2), reused 0 (delta 0), pack-reused 848\u001b[K\n",
            "Receiving objects: 100% (856/856), 968.78 KiB | 26.91 MiB/s, done.\n",
            "Resolving deltas: 100% (552/552), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogEx4Mbbhd2L"
      },
      "source": [
        "*Install* Prereq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emPqBiHhdJb"
      },
      "source": [
        "!pip install  essential_generators \n",
        "!pip install validators\n",
        "!pip install fonttools\n",
        "!pip install editdistance\n",
        "!pip install pyclipper\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqazGa7-hmzT"
      },
      "source": [
        "Loading the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7q9gxxEhm-8"
      },
      "source": [
        "%cd /content/keras-ocr/\n",
        "!gdown 'https://drive.google.com/uc?id=15fdLEOeUYZ8bnnj9tmsdlUvsCDm7sHgw' #detector_digit20_v11.h5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5sUPoumhsJ0"
      },
      "source": [
        "load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4saMTrX7htWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc08c625-b121-4fb6-8cc8-afaf167959fa"
      },
      "source": [
        "%cd /content/keras-ocr/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-ocr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEyMy1XKh0Eb"
      },
      "source": [
        "#!gdown 'https://drive.google.com/uc?id=15ukczpqJa4j7Gb_GilzBcvhtXyTN8vBS' #Ice_hockey_Dataset\n",
        "!gdown 'https://drive.google.com/uc?id=1MXnvzo4a_N0jtzlmNayxdZqAy-InfNUJ' #S_Basketball_Dataset\n",
        "#!gdown 'https://drive.google.com/uc?id=1iH28eYogUDNX8eMKdlwQY7cHYmSszG2t'  #S_Basketball_Dataset_with_small_numer\n",
        "\n",
        "#!gdown 'https://drive.google.com/uc?id=149hRNIKqN9o_cIZPnC-yb6RbyetjRrhQ' #combined_dataset_images_train_valid_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D15DBcmh2gz"
      },
      "source": [
        "#!unzip  /content/keras-ocr/Ice_hockey_Dataset.zip\n",
        "!unzip /content/keras-ocr/S_Basketball_Dataset.zip\n",
        "#!unzip /content/keras-ocr/combined_dataset_images_train_valid_test.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xKIeMXuh45D"
      },
      "source": [
        "#!rm /content/keras-ocr/test/*\n",
        "!rm /content/keras-ocr/output/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mGoOahDh8Rz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import keras_ocr\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjTRp2omh-YD"
      },
      "source": [
        "\n",
        "from keras_ocr import detection\n",
        "# keras-ocr will automatically download pretrained\n",
        "# weights for the detector and recognizer.\n",
        "detector = detection.Detector(weights_path='/content/keras-ocr/detector_digit20_v11.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvY66s2siBbE"
      },
      "source": [
        "\n",
        "import os.path\n",
        "\n",
        "# Get a set of three example images\n",
        "out_dir = '/content/keras-ocr/output/'\n",
        "#======generalize test\n",
        "img_dir = '/content/keras-ocr/S_Basketball_Dataset/'\n",
        "img_path_list = []\n",
        "img_name_lst = []\n",
        "for entry in os.listdir(img_dir):\n",
        "  if entry !='.ipynb_checkpoints':\n",
        "    img_file_path = os.path.join(img_dir, entry)\n",
        "    img_path_list.append(img_file_path)\n",
        "    img_name_lst.append(entry)\n",
        "\n",
        "count = 0\n",
        "for img_path in img_path_list:\n",
        "    #print(\"img_path\",img_path)\n",
        "    if not os.path.exists(img_path):\n",
        "        count +=1\n",
        "        continue \n",
        "    images = [\n",
        "        keras_ocr.tools.read(url) for url in [img_path]]\n",
        "    # # Make sure we have an image array to start with.\n",
        "    if not isinstance(images, np.ndarray):\n",
        "        images = [keras_ocr.tools.read(image) for image in images]\n",
        "     \n",
        "    # # # Make sure we have an image array to start with.\n",
        "    # if not isinstance(images, np.ndarray):\n",
        "    #     images = [cv2.merge([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY),cv2.cvtColor(image, cv2.COLOR_BGR2GRAY),cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)]) for image in images]\n",
        "    \n",
        "    # This turns images into (image, scale) tuples temporarily\n",
        "    #we will use resize_aspect_ratio(img, square_size, instead of resize_image\n",
        "    square_size =192\n",
        "    images = [ keras_ocr.tools.resize_aspect_ratio(image, square_size,mag_ratio=1) for image in images ]\n",
        "    ###========> resize_aspect_ratio_longest_side\n",
        "    #images = [ keras_ocr.tools.resize_aspect_ratio_longest_side(image, square_size,mag_ratio=1) for image in images ]\n",
        "    #images = [keras_ocr.tools.resize_image(image, max_scale=1, max_size=2048) for image in images]\n",
        "    max_height, max_width = np.array([image.shape[:2] for image, scale in images]).max(axis=0)\n",
        "    scales = [scale for _, scale in images]\n",
        "    images = np.array(\n",
        "        [keras_ocr.tools.pad(image, width=max_width, height=max_height) for image, _ in images])\n",
        "    detection_kwargs ={'detection_threshold':0.1,'text_threshold':0.1,'link_threshold':0.1}\n",
        "    if detection_kwargs is None:\n",
        "        detection_kwargs = {}\n",
        "\n",
        "    box_groups,score_map,link_map,rotation_angle =  detector.detect(images=images, **detection_kwargs)\n",
        "    box_groups = [\n",
        "        keras_ocr.tools.adjust_boxes(boxes=boxes, boxes_format='boxes', scale=1 /\n",
        "                            scale) if scale != 1 else boxes\n",
        "        for boxes, scale in zip(box_groups, scales)\n",
        "    ]\n",
        "    # # save results in txt files\n",
        "    # count =0\n",
        "    # for image, predictions in zip(images, box_groups):\n",
        "    # result directory\n",
        "    res_file = out_dir + \"res_\" + img_name_lst[count][:-4] + '.txt'\n",
        "    #count +=1\n",
        "    if not os.path.isdir(out_dir):\n",
        "        os.mkdir(out_dir)\n",
        "\n",
        "    with open(res_file, 'w') as f:\n",
        "        for i, box in enumerate(box_groups[0]):\n",
        "            poly = np.array(box).astype(np.int32).reshape((-1))\n",
        "            strResult = ','.join([str(p) for p in poly]) + '\\r\\n' #','+str(rotation_angle)+ \n",
        "            f.write(strResult)\n",
        "\n",
        "    image_cont = keras_ocr.tools.read(img_path_list[count])\n",
        "    for box in box_groups[0]:\n",
        "        cv2.polylines(img=image_cont,\n",
        "                      pts=box[np.newaxis].astype('int32'),\n",
        "                      color=(255, 100, 40),\n",
        "                      thickness=2,\n",
        "                      isClosed=True)\n",
        "    \n",
        "    #vis_img = keras_ocr.tools.drawBoxes(images[0],np.int32([box_groups[0]]),color=(255, 100, 40))\n",
        "    #img_saved_name = out_dir +'frm_'+str(count)+'_'+'.jpg'\n",
        "    img_saved_name = out_dir +img_name_lst[count][:-4]+'.jpg'\n",
        "    score_map_saved_name = out_dir +img_name_lst[count][:-4]+'_score_txt.jpg'\n",
        "    link_map_saved_name = out_dir +img_name_lst[count][:-4]+'_link.jpg'\n",
        "    count +=1\n",
        "    cv2.imwrite(img_saved_name,cv2.cvtColor(image_cont, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite(score_map_saved_name,score_map)\n",
        "    #cv2.imwrite(link_map_saved_name,link_map)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o8afbr9jPg4"
      },
      "source": [
        "# **Number Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WFikFrnjSyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d0047b-08be-408b-a248-bdd6219935ae"
      },
      "source": [
        "%cd /content/\n",
        "#!git clone https://github.com/clovaai/deep-text-recognition-benchmark\n",
        "!git clone https://github.com/ahmed-nady/deep-text-recognition-benchmark.git\n",
        "%cd deep-text-recognition-benchmark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 459, done.\u001b[K\n",
            "remote: Total 459 (delta 0), reused 0 (delta 0), pack-reused 459\u001b[K\n",
            "Receiving objects: 100% (459/459), 3.04 MiB | 34.21 MiB/s, done.\n",
            "Resolving deltas: 100% (280/280), done.\n",
            "/content/deep-text-recognition-benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AykAYRGijcHa"
      },
      "source": [
        "Next, download large model files from Google Drive, using hack: https://stackoverflow.com/questions/20665881/direct-download-from-google-drive-using-google-drive-api/32742700#32742700"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1O-DSbHjV9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049670d0-a135-46cf-fed9-53ef61bc4d87"
      },
      "source": [
        "models = {\n",
        "    #'None-ResNet-None-CTC.pth': 'https://drive.google.com/open?id=1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0',\n",
        "    #'None-VGG-BiLSTM-CTC.pth': 'https://drive.google.com/open?id=1GGC2IRYEMQviZhqQpbtpeTgHO_IXWetG',\n",
        "    #'None-VGG-None-CTC.pth': 'https://drive.google.com/open?id=1FS3aZevvLiGF1PFBm5SkwvVcgI6hJWL9',\n",
        "    #'TPS-ResNet-BiLSTM-Attn-case-sensitive.pth': 'https://drive.google.com/open?id=1ajONZOgiG9pEYsQ-eBmgkVbMDuHgPCaY',\n",
        "    'TPS-ResNet-BiLSTM-Attn.pth': 'https://drive.google.com/open?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9'#,\n",
        "    #'TPS-ResNet-BiLSTM-CTC.pth': 'https://drive.google.com/open?id=1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0',\n",
        "}\n",
        "\n",
        "for k, v in models.items():\n",
        "  doc_id = v[v.find('=')+1:]\n",
        "  !curl -c /tmp/cookies \"https://drive.google.com/uc?export=download&id=$doc_id\" > /tmp/intermezzo.html\n",
        "  !curl -L -b /tmp/cookies \"https://drive.google.com$(cat /tmp/intermezzo.html | grep -Po 'uc-download-link\" [^>]* href=\"\\K[^\"]*' | sed 's/\\&amp;/\\&/g')\" > $k\n",
        "\n",
        "!ls -al *.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3257    0  3257    0     0  13348      0 --:--:-- --:--:-- --:--:-- 13348\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3264      0 --:--:-- --:--:-- --:--:--  3264\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  189M    0  189M    0     0  45.2M      0 --:--:--  0:00:04 --:--:-- 54.0M\n",
            "-rw-r--r-- 1 root root 198678680 Dec 17 01:03 TPS-ResNet-BiLSTM-Attn.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg_DMGAJjgjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdae89da-9855-4983-dcb7-1d4ad5cc8231"
      },
      "source": [
        "%cd /content/deep-text-recognition-benchmark\n",
        "!mkdir demo_image_numbers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5EpI1N2iHW0"
      },
      "source": [
        "# **Crop txt prediction bboxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcZtiLzRmwQN"
      },
      "source": [
        "img_dir = '/content/keras-ocr/Ice_hockey_Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRibbNpicED"
      },
      "source": [
        "import shutil, os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "pred_txt_dir = '/content/keras-ocr/output/'\n",
        "saved_dir = '/content/deep-text-recognition-benchmark/demo_image_numbers/'\n",
        "#img_dir = 'F:\\\\PhD\\\\Dataset\\\\ice_hockey_tracklets_5fps\\\\Ice_hockey_Dataset\\\\'\n",
        "\n",
        "#img_dir = 'F:\\\\PhD\\\\Dataset\\\\combined_second_third_dataset\\\\dataset_Separation_small_nums_Gerke\\\\test\\\\'\n",
        "# img_dir  ='F:\\\\PhD\\\\Dataset\\\\soccerDataset\\\\'\n",
        "#img_dir = 'F:\\\\PhD\\\\Dataset\\\\gt_camera7_basketball_tracklets_5fps\\\\S_Basketball_Dataset\\\\'\n",
        "count =0\n",
        "for entry in os.listdir(pred_txt_dir):\n",
        "\t\n",
        "    if entry.endswith('.txt'):\n",
        "        txt_file_path = os.path.join(pred_txt_dir, entry)\n",
        "        filename, file_ext = os.path.splitext(os.path.basename(txt_file_path))\n",
        "        # temp = filename.split('_')[1:] \n",
        "        # image_id='_'.join(temp)\n",
        "        image_path = img_dir+entry[4:-4]+'.png'\n",
        "        #print(image_path)\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        if img is None:\n",
        "            continue\n",
        "        with open(txt_file_path) as f:\n",
        "            lines = f.readlines() \n",
        "            count +=1\n",
        "            for i,line in enumerate(lines):\n",
        "                line = line.rstrip()\n",
        "                rec_img_file = saved_dir + \"rec_\" + entry[4:-4] +'_'+str(i)+ '.png'\n",
        "                points_coordinates = line.split(',')\n",
        "                cnt = np.array([\n",
        "                        [[int(points_coordinates[0]), int(points_coordinates[1])]],\n",
        "                        [[int(points_coordinates[2]), int(points_coordinates[3])]],\n",
        "                        [[int(points_coordinates[4]),int(points_coordinates[5])]],\n",
        "                        [[int(points_coordinates[6]), int(points_coordinates[7])]]\n",
        "                    ])\n",
        "\n",
        "                x,y,w,h = cv2.boundingRect(cnt)\n",
        "                img_h,img_w,_ = img.shape\n",
        "                if x <0:\n",
        "                  x=0\n",
        "                if y < 0 :\n",
        "                  y =0\n",
        "                if x+w >img_w:\n",
        "                  w = w-((x+w)-img_w)\n",
        "                if y+h > img_h:\n",
        "                  h = h -((y+h)-img_h)\n",
        "                roi = img[y:y+h,x:x+w]\n",
        "                #print(\"x,y,w,h\",x,y,w,h)\n",
        "                #print(\"img\",img.shape)\n",
        "                if roi is None:\n",
        "                    continue\n",
        "                #print(roi)\n",
        "                cv2.imwrite(rec_img_file, roi)\n",
        "        #print(\"count\",count,image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZrydH8NXVGC",
        "outputId": "8efa1717-c558-44b4-911c-b895fee11cb4"
      },
      "source": [
        "%cd /content/deep-text-recognition-benchmark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnbmo3sCkHpR"
      },
      "source": [
        "**TPS-ResNet-BiLSTM-Attn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFCGgurQkLjJ"
      },
      "source": [
        "output = !CUDA_VISIBLE_DEVICES=0 python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder demo_image_numbers/  --batch_size 1088 \\\n",
        "--saved_model TPS-ResNet-BiLSTM-Attn.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkFQ_DsamCbq"
      },
      "source": [
        "# **Number detection and recognition evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK3actucmJVu"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYHACZiPmOBh"
      },
      "source": [
        "def get_predicted_text_v2(txt_dir,pred_txt_file_path):\n",
        "\ttxt_pred =[]\n",
        "\ttxt_pred_conf =[]\n",
        "\n",
        "\tdf = pd.read_csv(pred_txt_file_path,sep=\"\\t\")\n",
        "\t#print(df)\n",
        "\n",
        "\n",
        "\t#get image names\n",
        "\t\n",
        "\timg_dict = {}\n",
        "\n",
        "\tfor entry in os.listdir(txt_dir):\n",
        "\t\tif entry.endswith('.txt'):\n",
        "\t\t\timg_file_path = os.path.join(txt_dir, entry)\n",
        "\t\t\tfilename, file_ext = os.path.splitext(os.path.basename(img_file_path))\n",
        "\t\t\timage_id='_'.join(filename.split('_')[1:])\n",
        "\t\t\ttxt_save_file ='rec_'+image_id\n",
        "\t        #img_save_file ='rec_'+filename[3:]\n",
        "\t\t\timg_dict[txt_save_file] = ''\n",
        "\t\telse:\n",
        "\t\t\ttxt_save_file ='rec_'+entry[0:-4]\n",
        "\t\t\t#img_save_file ='rec_'+filename[3:]\n",
        "\t\t\timg_dict[txt_save_file] = ''\n",
        "\n",
        "\tfor ind, row in df.iterrows():\n",
        "\t  \n",
        "\t  # print(\"ind\",ind)\n",
        "\t  # print(\"row\",row)\n",
        "\t  number_flag = False\n",
        "\t  # if ind <3:\n",
        "\t  # \tcontinue\n",
        "\t  filename =  row[0]\n",
        "\t  label = row[1].strip()\n",
        "\t  conf = row[2]\n",
        "\t  # print(\"filename========\",filename , (label),(conf))\n",
        "\t  # print(\"------\",conf)\n",
        "\t  if label.isnumeric():\n",
        "\t  \t#this means the detected text is number not string\n",
        "\t  \tnumber_flag =True \n",
        "\n",
        "\t  # make result file list\n",
        "\t  filenameWithoutExt, file_ext = os.path.splitext(os.path.basename(filename))\n",
        "\t  split_file_name = filenameWithoutExt.split('_')\n",
        "\n",
        "\t  img_dic_idx = filenameWithoutExt[:-2]\n",
        "\t   \n",
        "\t  #print(img_dic_idx)\n",
        "\t  #print(\"filenameWithoutExt.split('_')[2]\",filenameWithoutExt.split('_'))\n",
        "\t  #print(\"split_file_name\",split_file_name)\n",
        "\t  \n",
        "\t  if split_file_name[-1] =='0':\n",
        "\t  \t if number_flag :\n",
        "\t\t  \t txt_pred.append(label)\n",
        "\t\t  \t txt_pred_conf.append(conf)\n",
        "\t\t  \t img_dict[img_dic_idx] = label\n",
        "\t  \t else:\n",
        "\t\t  \t txt_pred.append('000')\n",
        "\t\t  \t txt_pred_conf.append(0)\n",
        "\n",
        "\n",
        "\t  \t  \n",
        "\t  else:\n",
        "\t  \t #keep only one prediction per image\n",
        "\t  \t #print(\"txt_pred_conf\",txt_pred_conf,conf,split_file_name)\n",
        "\t  \t if conf > txt_pred_conf[-1] and number_flag  : #conf >txt_pred_conf[-1] and number_flag\n",
        "\t  \t \ttxt_pred[-1] = label\n",
        "\t  \t \ttxt_pred_conf[-1] = conf\n",
        "\t  \t \timg_dict[img_dic_idx] = label\n",
        "\t  \t   \n",
        "\n",
        "\t#print(\"len of text prediction\",len(txt_pred),txt_pred)\n",
        "\t#print(\"Img with text\",img_dict)\n",
        "\treturn img_dict\n",
        "\n",
        "def get_ground_truth(img_dir):\n",
        "\n",
        "\timg_dict = {}\n",
        "\n",
        "\tfor entry in os.listdir(img_dir):\n",
        "\t\tif entry.endswith('.png'):\n",
        "\t\t\ttxt_save_file ='rec_'+entry[0:-4]\n",
        "\t        #img_save_file ='rec_'+filename[3:]\n",
        "\t\t\timgClass = entry.split('_')[1]\n",
        "\t\t\t# # we use metrics for positive samples\n",
        "\t\t\t# if imgClass !='None':\n",
        "\t\t\t# \timg_dict[txt_save_file] =  imgClass\n",
        "\t\t\timg_dict[txt_save_file] =  imgClass if imgClass !='None' else ''\n",
        "\n",
        "\treturn img_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt5SotCSnDc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c65e79-f993-4d6c-ca88-b3eea488adc7"
      },
      "source": [
        "#img_dir = 'F:\\\\PhD\\\\Dataset\\\\gt_camera7_basketball_tracklets_5fps\\\\S_Basketball_Dataset_with_small_numer\\\\'\n",
        "#txt_dir = 'F:\\\\PhD\\\\Dataset\\\\first_data_set\\\\gt\\\\'\n",
        "rec_file = '/content/deep-text-recognition-benchmark/log_demo_result.txt'  \n",
        "pred_img_dict = get_predicted_text_v2(img_dir,rec_file)\n",
        "# get image class from their names\n",
        "gt_img_dict = get_ground_truth(img_dir)\n",
        "# #get image class from the content of text\n",
        "\n",
        "# iterate over gt_img_dict\n",
        "txt_pred =[]\n",
        "txt_gt =[]\n",
        "#missed_labels_count =0\n",
        "for img_name,gt_label in gt_img_dict.items():\n",
        "\t# if gt_label =='' and pred_img_dict[img_name]=='':\n",
        "\t# \tmissed_labels_count+=1\n",
        "\t#print(\"img_name========\",img_name,gt_label,pred_img_dict[img_name])\n",
        "\ttxt_gt.append(gt_label)\n",
        "\ttxt_pred.append(pred_img_dict[img_name])\n",
        "\n",
        "print(\"set(y_test) - set(y_pred)\",set(txt_gt) - set(txt_pred))\n",
        "\n",
        "#get Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy\",accuracy_score(txt_gt, txt_pred))\n",
        "\n",
        "actual_classes =list(set(txt_gt))\n",
        "pred_classes = list(set(txt_pred))\n",
        "\n",
        "class_labels = sorted(list(set(actual_classes+pred_classes)))\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(txt_gt, txt_pred,labels=np.unique(class_labels))) #labels=pred_classes\n",
        "\n",
        "#get_eval_metric(txt_gt, txt_pred)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "print(confusion_matrix(txt_gt, txt_pred))\n",
        "# plot_confusion_matrix(None, txt_gt, txt_pred)  # doctest: +SKIP\n",
        "# plt.show()\n",
        "from sklearn.metrics import recall_score\n",
        "print(\"====\",recall_score(txt_gt, txt_pred, average='macro'))\n",
        "\n",
        "print(\"micro\",recall_score(txt_gt, txt_pred, average='micro'))\n",
        "print(\"weighted\",recall_score(txt_gt, txt_pred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "set(y_test) - set(y_pred) {'18'}\n",
            "Accuracy 0.8509544787077826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.86      0.98      0.92       987\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.67      0.27      0.39        22\n",
            "          10       0.88      0.39      0.54        18\n",
            "         100       0.00      0.00      0.00         0\n",
            "          11       0.67      0.16      0.26        25\n",
            "         112       0.00      0.00      0.00         0\n",
            "         115       0.00      0.00      0.00         0\n",
            "          12       0.50      0.29      0.36         7\n",
            "          13       0.94      0.63      0.75        46\n",
            "         133       0.00      0.00      0.00         0\n",
            "          14       0.80      0.67      0.73        18\n",
            "          15       0.75      0.21      0.33        14\n",
            "          17       0.92      0.76      0.83        29\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.88      0.93      0.90        15\n",
            "           2       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       1.00      0.71      0.83        24\n",
            "         210       0.00      0.00      0.00         0\n",
            "           3       0.89      0.42      0.57        19\n",
            "           4       0.88      0.56      0.68        54\n",
            "         412       0.00      0.00      0.00         0\n",
            "         415       0.00      0.00      0.00         0\n",
            "          44       0.00      0.00      0.00         0\n",
            "           5       0.89      0.47      0.62        36\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       1.00      0.38      0.55        37\n",
            "           9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.85      1362\n",
            "   macro avg       0.45      0.29      0.34      1362\n",
            "weighted avg       0.86      0.85      0.83      1362\n",
            "\n",
            "[[972   2   3   1   0   0   0   1   0   2   0   1   0   0   0   0   1   1\n",
            "    0   0   0   0   0   0   0   2   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 13   0   6   0   0   0   0   0   2   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  8   0   0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 18   0   0   0   0   4   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   0   0   2   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   1   0   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [ 11   0   0   0   0   1   0   0   0  29   1   0   1   1   0   0   1   0\n",
            "    0   0   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [ 10   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0  22   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   17   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   8   1   0   0   0   0   0   1   0   0]\n",
            " [ 20   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0\n",
            "    0   0   0  30   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0  17   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   1   0  14   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   2]]\n",
            "==== 0.294367206218647\n",
            "micro 0.8509544787077826\n",
            "weighted 0.8509544787077826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgjt_jjUWpmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9397c02-895e-4cf4-b10b-16e40914c038"
      },
      "source": [
        "!rm /content/deep-text-recognition-benchmark/demo_image_numbers/*\n",
        "!rm /content/keras-ocr/output/*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/deep-text-recognition-benchmark/demo_image_numbers/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBo7iFxykR-R"
      },
      "source": [
        "Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8bIUeNKkU_B"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame()\n",
        "for ind, row in enumerate(output[output.index('image_path               \\tpredicted_labels         \\tconfidence score')+4:]):\n",
        "  row = row.split('\\t')\n",
        "  if len(row) <2 or 'image_path'==row[0].strip():\n",
        "    continue\n",
        "  #print(row,type(row))\n",
        "  filename = row[0].strip()\n",
        "  label = row[1].strip()\n",
        "  conf = row[2].strip()\n",
        "  #print(filename)\n",
        "  img = Image.open(filename)\n",
        "  img_buffer = io.BytesIO()\n",
        "  img.save(img_buffer, format=\"PNG\")\n",
        "  imgStr = base64.b64encode(img_buffer.getvalue()).decode(\"utf-8\") \n",
        "\n",
        "  data.loc[ind, 'img'] = '<img src=\"data:image/png;base64,{0:s}\">'.format(imgStr)\n",
        "  data.loc[ind, 'id'] = filename\n",
        "  data.loc[ind, 'label'] = label\n",
        "  data.loc[ind, 'conf'] = conf\n",
        "\n",
        "html_all = data.to_html(escape=False)\n",
        "display(HTML(html_all))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnzk5caNgFiS"
      },
      "source": [
        "**save output of detector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrL21xSwgJ7t"
      },
      "source": [
        "!zip -r /content/numbers_dataset_mask_v11_img_192.zip /content/keras-ocr/output\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.download('/content/numbers_dataset_mask_v11_img_192.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}